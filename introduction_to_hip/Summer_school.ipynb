{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><h1>Summer School --- HIP C/C++</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prerequisites\n",
    "\n",
    "To get the most out of this lab you should already be able to:\n",
    "\n",
    "- Declare variables, write loops, and use if / else statements in C.\n",
    "- Define and invoke functions in C.\n",
    "- Allocate arrays in C.\n",
    "\n",
    "No previous HIP knowledge is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Objectives\n",
    "\n",
    "By the time you complete this lab, you will be able to:\n",
    "\n",
    "- Write, compile, and run C/C++ programs that both call CPU functions and **launch** GPU **kernels**.\n",
    "- Control parallel **thread hierarchy** using **execution configuration**.\n",
    "- Refactor serial loops to execute their iterations in parallel on a GPU.\n",
    "- Allocate and free memory available to both CPUs and GPUs.\n",
    "- Handle errors generated by HIP code.\n",
    "- Accelerate CPU-only applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Accelerated Systems\n",
    "\n",
    "*Accelerated systems*, also referred to as *heterogeneous systems*, are those composed of both CPUs and GPUs. Accelerated systems run CPU programs which in turn, launch functions that will benefit from the massive parallelism providied by GPUs. This lab environment is an accelerated system which includes an AMD GPU. Information about this GPU can be queried with the `rocm-smi` (*Systems Management Interface*) command line command. Issue the `rocm-smi` command now, by `CTRL` + clicking on the code execution cell below. You will find these cells throughout this lab any time you need to execute code. The output from running the command will be printed just below the code execution cell after the code runs. After running the code execution block immediately below, take care to find and note the (VRAM, compute utilization, temperature, etc) of the GPU in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========================================= ROCm System Management Interface =========================================\n",
      "=================================================== Concise Info ===================================================\n",
      "Device  [Model : Revision]    Temp    Power     Partitions      SCLK  MCLK     Fan  Perf  PwrCap       VRAM%  GPU%  \n",
      "\u001b[3m        Name (20 chars)       (Edge)  (Socket)  (Mem, Compute)                                                      \u001b[0m\n",
      "====================================================================================================================\n",
      "0       [0xb002 : 0xc1]       33.0Â°C  11.189W   N/A, N/A        None  2800Mhz  0%   auto  Unsupported    3%   1%    \n",
      "        0x15bf                                                                                                      \n",
      "====================================================================================================================\n",
      "=============================================== End of ROCm SMI Log ================================================\n"
     ]
    }
   ],
   "source": [
    "!rocm-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Writing Application Code for the GPU\n",
    "\n",
    "HIP is a C++ Runtime API and Kernel Language that allows developers to create portable applications for AMD and NVIDIA GPUs from single source code.\n",
    "\n",
    "Below is a `.cpp` file. It contains two functions, the first which will run on the CPU, the second which will run on the GPU. Spend a little time identifying the differences between the functions, both in terms of how they are defined, and how they are invoked.\n",
    "\n",
    "```cpp\n",
    "void CPUFunction()\n",
    "{\n",
    "  printf(\"This function is defined to run on the CPU.\\n\");\n",
    "}\n",
    "\n",
    "__global__ void GPUFunction()\n",
    "{\n",
    "  printf(\"This function is defined to run on the GPU.\\n\");\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  CPUFunction();\n",
    "\n",
    "  GPUFunction<<<1, 1>>>();\n",
    "  HIPDeviceSynchronize();\n",
    "}\n",
    "```\n",
    "\n",
    "Here are some important lines of code to highlight, as well as some other common terms used in accelerated computing:\n",
    "\n",
    "`__global__ void GPUFunction()`\n",
    "  - The `__global__` keyword indicates that the following function will run on the GPU, and can be invoked **globally**, which in this context means either by the CPU, or, by the GPU.\n",
    "  - Often, code executed on the CPU is referred to as **host** code, and code running on the GPU is referred to as **device** code.\n",
    "  - Notice the return type `void`. It is required that functions defined with the `__global__` keyword return type `void`.\n",
    "\n",
    "`GPUFunction<<<1, 1>>>();`\n",
    "  - Typically, when calling a function to run on the GPU, we call this function a **kernel**.\n",
    "  - When launching a kernel, we must provide an **execution configuration**, which is done by using the `<<< ... >>>` syntax just prior to passing the kernel any expected arguments.\n",
    "  - At a high level, execution configuration allows programmers to specify the **thread hierarchy** for a kernel launch, which defines the number of thread groupings (called **blocks**), as well as how many **threads** to execute in each block. Execution configuration will be explored at great length later in the lab, but for the time being, notice the kernel is launching with `1` block of threads (the first execution configuration argument) which contains `1` thread (the second configuration argument).\n",
    "\n",
    "`hipDeviceSynchronize();`\n",
    "  - Unlike much C/C++ code, launching kernels is **asynchronous**: the CPU code will continue to execute *without waiting for the kernel launch to complete*.\n",
    "  - A call to `HIPDeviceSynchronize`, a function provided by the HIP runtime, will cause the host (CPU) code to wait until the device (GPU) code completes, and only then resume execution on the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Compiling and Running Accelerated HIP Code\n",
    "\n",
    "The HIP platform ships with the [**ROCm HIP Compiler**](https://rocm.docs.amd.com/projects/HIPCC/en/latest/index.html) `hipcc`, which can compile HIP accelerated applications, both the host, and the device code they contain. For the purposes of this lab, `hipcc` discussion with be pragmatically scoped to suit our immediate needs. After completing the lab, For anyone interested in a deeper dive into `hipcc`, start with [the documentation](https://rocm.docs.amd.com/projects/HIPCC/en/latest/index.html).\n",
    "\n",
    "`hipcc` will be very familiar to experienced `gcc` users. Compiling, for example, a `some-HIP.cpp` file, is simply:\n",
    "\n",
    "`hipcc -o out some-HIP.cpp `\n",
    "  - `hipcc` is the command line command for using the `hipcc` compiler.\n",
    "  - `some-HIP.cpp` is passed as the file to compile.\n",
    "  - The `-o` flag is used to specify the output file for the compiled program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Example01: Accelerate Vector Addition Application\n",
    "\n",
    "The following challenge involves accelerating a CPU-only vector addition program, which, while not the most sophisticated program, will give you an opportunity to focus on what you have learned about GPU-accelerating an application with HIP.\n",
    "\n",
    "[`01_vector_addition.cpp`](./examples/01_vector_addition/vector_addition.cpp) contains a functioning CPU-only vector addition application. You need to write a HIP kernel on the GPU and to do its work in parallel.\n",
    "\n",
    "![vec_add_01](./images/vec_add_01.png)\n",
    "\n",
    "![vec_add_02](./images/vec_add_02.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "/* --------------------------------------------------\n",
    "Include lib\n",
    "-------------------------------------------------- */\n",
    "#include <stdio.h>\n",
    "#include <math.h>\n",
    "#include \"hip/hip_runtime.h\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "/* --------------------------------------------------\n",
    "vector addition kernel\n",
    "-------------------------------------------------- */\n",
    "__global__ void vector_addition(double *A, double *B, double *C, int n)\n",
    "{\n",
    "    int id = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if (id < n) C[id] = A[id] + B[id];\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "/* --------------------------------------------------\n",
    "Main program\n",
    "-------------------------------------------------- */\n",
    "int main(int argc, char *argv[]){\n",
    "\n",
    "    /* Size of array */\n",
    "    int N = 1024 * 1024;\n",
    "\n",
    "    /* Bytes in array in double precision */\n",
    "    size_t bytes = N * sizeof(double);\n",
    "\n",
    "    /* Allocate memory for host arrays */\n",
    "    double *h_A = (double*)malloc(bytes);\n",
    "    double *h_B = (double*)malloc(bytes);\n",
    "    double *h_C = (double*)malloc(bytes);\n",
    "\n",
    "    /* Initialize host arrays */\n",
    "    for(int i=0; i<N; i++){\n",
    "        h_A[i] = sin(i) * sin(i); \n",
    "        h_B[i] = cos(i) * cos(i);\n",
    "        h_C[i] = 0.0;\n",
    "    }    \n",
    "\n",
    "    /* Allocate memory for device arrays */\n",
    "    double *d_A, *d_B, *d_C;\n",
    "    hipMalloc(&d_A, bytes);\n",
    "    hipMalloc(&d_B, bytes);\n",
    "    hipMalloc(&d_C, bytes);\n",
    "\n",
    "    /* Copy data from host arrays to device arrays */\n",
    "    hipMemcpy(d_A, h_A, bytes, hipMemcpyHostToDevice);\n",
    "    hipMemcpy(d_B, h_B, bytes, hipMemcpyHostToDevice);\n",
    "    hipMemcpy(d_C, h_C, bytes, hipMemcpyHostToDevice);\n",
    "\n",
    "    /* Set kernel configuration parameters\n",
    "           thr_per_blk: number of threads per thread block\n",
    "           blk_in_grid: number of thread blocks in grid */\n",
    "    int thr_per_blk = 256;\n",
    "    int blk_in_grid = ceil( float(N) / thr_per_blk );\n",
    "\n",
    "    /* Launch vector addition kernel */\n",
    "    vector_addition<<<blk_in_grid, thr_per_blk>>>(d_A, d_B, d_C, N);\n",
    "\n",
    "    /* Copy data from device array to host array (only need result, d_C) */\n",
    "    hipMemcpy(h_C, d_C, bytes, hipMemcpyDeviceToHost);\n",
    "\n",
    "    /* Check for correct results */\n",
    "    double sum       = 0.0;\n",
    "    double tolerance = 1.0e-14;\n",
    "\n",
    "    for(int i=0; i<N; i++){\n",
    "        sum = sum + h_C[i];\n",
    "    } \n",
    "\n",
    "    if( fabs( (sum / N) - 1.0 ) > tolerance ){\n",
    "        printf(\"Error: Sum/N = %0.2f instead of ~1.0\\n\", sum / N);\n",
    "        exit(1);\n",
    "    }\n",
    "\n",
    "    /* Free CPU memory */\n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(h_C);\n",
    "\n",
    "    /* Free Device memory */\n",
    "    hipFree(d_A);\n",
    "    hipFree(d_B);\n",
    "    hipFree(d_C);\n",
    "\n",
    "    printf(\"\\n==============================\\n\");\n",
    "    printf(\"__SUCCESS__\\n\");\n",
    "    printf(\"------------------------------\\n\");\n",
    "    printf(\"N                : %d\\n\", N);\n",
    "    printf(\"Blocks in Grid   : %d\\n\", blk_in_grid);\n",
    "    printf(\"Threads per Block: %d\\n\", thr_per_blk);\n",
    "    printf(\"==============================\\n\\n\"); \n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "__SUCCESS__\n",
      "------------------------------\n",
      "N                : 1048576\n",
      "Blocks in Grid   : 4096\n",
      "Threads per Block: 256\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p build\n",
    "!hipcc --offload-arch=gfx908 -Wno-unused-result -o build/vector_add_basic examples/01_vector_addition/vector_addition.cpp && build/vector_add_basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise01: Error check\n",
    "\n",
    "Through the example, you have learned the basic operation mode of array addition. Now there is an error in the following part of the code. Please find it and modify it so that the program generates the correct answer. You can find the source code in [`01_error_check.cpp`](./exercises/01_error_check/vector_addition.cpp).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "#include <stdio.h>\n",
    "#include <math.h>\n",
    "#include \"hip/hip_runtime.h\"\n",
    "\n",
    "/* Macro for checking GPU API return values */\n",
    "#define gpuCheck(call)                                                                          \\\n",
    "do{                                                                                             \\\n",
    "    hipError_t gpuErr = call;                                                                   \\\n",
    "    if(hipSuccess != gpuErr){                                                                   \\\n",
    "        printf(\"GPU API Error - %s:%d: '%s'\\n\", __FILE__, __LINE__, hipGetErrorString(gpuErr)); \\\n",
    "        exit(1);                                                                                \\\n",
    "    }                                                                                           \\\n",
    "}while(0)\n",
    "\n",
    "/* --------------------------------------------------\n",
    "Vector addition kernel\n",
    "-------------------------------------------------- */\n",
    "__global__ void vector_addition(double *A, double *B, double *C, int n)\n",
    "{\n",
    "    int id = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if (id < n) C[id] = A[id] + B[id];\n",
    "}\n",
    "\n",
    "/* --------------------------------------------------\n",
    "Main program\n",
    "-------------------------------------------------- */\n",
    "int main(int argc, char *argv[]){\n",
    "\n",
    "    /* Size of array */\n",
    "    int N = 1024 * 1024;\n",
    "\n",
    "    /* Bytes in array in double precision */\n",
    "    size_t bytes = N * sizeof(double);\n",
    "\n",
    "    /* Allocate memory for host arrays */\n",
    "    double *h_A = (double*)malloc(bytes);\n",
    "    double *h_B = (double*)malloc(bytes);\n",
    "    double *h_C = (double*)malloc(bytes);\n",
    "\n",
    "    /* Initialize host arrays */\n",
    "    for(int i=0; i<N; i++){\n",
    "        h_A[i] = sin(i) * sin(i); \n",
    "        h_B[i] = cos(i) * cos(i);\n",
    "        h_C[i] = 0.0;\n",
    "    }    \n",
    "\n",
    "    /* Allocate memory for device arrays */\n",
    "    double *d_A, *d_B, *d_C;\n",
    "    gpuCheck( hipMalloc(&d_A, bytes) );\n",
    "    gpuCheck( hipMalloc(&d_B, bytes) );\n",
    "    gpuCheck( hipMalloc(&d_C, bytes) );\n",
    "\n",
    "    /* Copy data from host arrays to device arrays */\n",
    "    gpuCheck( hipMemcpy(h_A, h_A, bytes, hipMemcpyHostToDevice) );\n",
    "    gpuCheck( hipMemcpy(d_B, h_B, bytes, hipMemcpyHostToDevice) );\n",
    "    gpuCheck( hipMemcpy(d_C, h_C, bytes, hipMemcpyHostToDevice) );\n",
    "\n",
    "    /* Set kernel configuration parameters\n",
    "           thr_per_blk: number of threads per thread block\n",
    "           blk_in_grid: number of thread blocks in grid */\n",
    "    int thr_per_blk = 256;\n",
    "    int blk_in_grid = ceil( float(N) / thr_per_blk );\n",
    "\n",
    "    /* Launch vector addition kernel */\n",
    "    vector_addition<<<blk_in_grid, thr_per_blk>>>(d_A, d_B, d_C, N);\n",
    "\n",
    "    /* Check for kernel launch errors */\n",
    "    gpuCheck( hipGetLastError() );\n",
    "\n",
    "    /* Check for kernel execution errors */\n",
    "    gpuCheck ( hipDeviceSynchronize() );\n",
    "\n",
    "    /* Copy data from device array to host array (only need result, d_C) */\n",
    "    gpuCheck( hipMemcpy(h_C, d_C, bytes, hipMemcpyDeviceToHost) );\n",
    "\n",
    "    /* Check for correct results */\n",
    "    double sum       = 0.0;\n",
    "    double tolerance = 1.0e-14;\n",
    "\n",
    "    for(int i=0; i<N; i++){\n",
    "        sum = sum + h_C[i];\n",
    "    } \n",
    "\n",
    "    if( fabs( (sum / N) - 1.0 ) > tolerance ){\n",
    "        printf(\"Error: Sum/N = %0.2f instead of ~1.0\\n\", sum / N);\n",
    "        exit(1);\n",
    "    }\n",
    "\n",
    "    /* Free CPU memory */\n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(h_C);\n",
    "\n",
    "    /* Free Device memory */\n",
    "    gpuCheck( hipFree(d_A) );\n",
    "    gpuCheck( hipFree(d_B) );\n",
    "    gpuCheck( hipFree(d_C) );\n",
    "\n",
    "    printf(\"\\n==============================\\n\");\n",
    "    printf(\"__SUCCESS__\\n\");\n",
    "    printf(\"------------------------------\\n\");\n",
    "    printf(\"N                : %d\\n\", N);\n",
    "    printf(\"Blocks in Grid   : %d\\n\",  blk_in_grid);\n",
    "    printf(\"Threads per Block: %d\\n\",  thr_per_blk);\n",
    "    printf(\"==============================\\n\\n\");\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Instructions:`\n",
    "\n",
    "You can find the solution in ./exercises/01_error_check/solution/vector_addition.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and test your program \n",
    "!hipcc --offload-arch=gfx908 -Wno-unused-result -o build/error_check exercises/01_error_check/vector_addition.cpp && build/error_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise02: Increments each element of an array\n",
    "\n",
    "In this exercise, you will be working with a simple HIP (Heterogeneous-Compute Interface for Portability) program that increments each element of an array by one using GPU acceleration. The program is mostly complete, but there is one part that you need to implement. You can find the source code in [`02_add_one.cpp`](./exercises/02_add_d2h_data_transfer/add_one.cpp).\n",
    "\n",
    "`Background:`\n",
    "\n",
    "The program performs the following steps:\n",
    "1. Defines a kernel function add_one that adds one to each element of an integer array.\n",
    "2. Allocates memory on the host (CPU) for an array of size N.\n",
    "3. Initializes the host array elements to zero.\n",
    "4. Allocates memory on the device (GPU) for an array of the same size.\n",
    "5. Copies the data from the host array to the device array.\n",
    "6. Configures the kernel launch parameters (number of threads per block and number of blocks in the grid).\n",
    "7. Launches the kernel to execute on the device.\n",
    "8. Copies the results back from the device array to the host array.\n",
    "9. Verifies the results.\n",
    "10. Frees the allocated memory on both the host and the device.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "#include <stdio.h>\n",
    "#include <math.h>\n",
    "#include \"hip/hip_runtime.h\"\n",
    "\n",
    "/* Macro for checking GPU API return values */\n",
    "#define gpuCheck(call)                                                                          \\\n",
    "do{                                                                                             \\\n",
    "    hipError_t gpuErr = call;                                                                   \\\n",
    "    if(hipSuccess != gpuErr){                                                                   \\\n",
    "        printf(\"GPU API Error - %s:%d: '%s'\\n\", __FILE__, __LINE__, hipGetErrorString(gpuErr)); \\\n",
    "        exit(1);                                                                                \\\n",
    "    }                                                                                           \\\n",
    "}while(0)\n",
    "\n",
    "/* --------------------------------------------------\n",
    "Add one kernel\n",
    "-------------------------------------------------- */\n",
    "__global__ void add_one(int *A, int n)\n",
    "{\n",
    "    int id = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if (id < n) A[id] = A[id] + 1;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Task:`\n",
    "\n",
    "Your task is to complete the part of the program that copies the data back from the device array to the host array. The function to use is `hipMemcpy`, which has the following definition:\n",
    "```c\n",
    "hipError_t hipMemcpy(void* destination_buffer,\n",
    "                     void* source_buffer,\n",
    "                     size_t num_bytes_to_copy,\n",
    "                     hipMemcpyKind kind);\n",
    "```\n",
    "Refer to the existing `hipMemcpy` call used to copy data from the host to the device as a guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "/* --------------------------------------------------\n",
    "Main program\n",
    "-------------------------------------------------- */\n",
    "int main(int argc, char *argv[]){\n",
    "\n",
    "    /* Size of array */\n",
    "    int N = 1024 * 1024;\n",
    "\n",
    "    /* Bytes in N ints */\n",
    "    size_t bytes = N * sizeof(int);\n",
    "\n",
    "    /* Allocate memory for host array */\n",
    "    int *h_A = (int*)malloc(bytes);\n",
    "\n",
    "    /* Initialize host arrays */\n",
    "    for(int i=0; i<N; i++){\n",
    "        h_A[i] = 0; \n",
    "    }    \n",
    "\n",
    "    /* Allocate memory for device array */\n",
    "    int *d_A;\n",
    "    gpuCheck( hipMalloc(&d_A, bytes) );\n",
    "\n",
    "    /* Copy data from host array to device array */\n",
    "    gpuCheck( hipMemcpy(d_A, h_A, bytes, hipMemcpyHostToDevice) );\n",
    "\n",
    "    /* Set kernel configuration parameters\n",
    "           thr_per_blk: number of threads per thread block\n",
    "           blk_in_grid: number of thread blocks in grid */\n",
    "    int thr_per_blk = 256;\n",
    "    int blk_in_grid = ceil( float(N) / thr_per_blk );\n",
    "\n",
    "    /* Launch kernel */\n",
    "    add_one<<<blk_in_grid, thr_per_blk>>>(d_A, N);\n",
    "\n",
    "    /* Check for kernel launch errors */\n",
    "    gpuCheck( hipGetLastError() );\n",
    "\n",
    "    /* Check for kernel execution errors */\n",
    "    gpuCheck ( hipDeviceSynchronize() );\n",
    "\n",
    "    /* Copy data from device array to host array */\n",
    "\n",
    "    // /////////////////////////////////////////////////////////\n",
    "    // TODO: Add hipMemcpy call here using the following\n",
    "    //       definition.\n",
    "    //\n",
    "    //       hipError_t hipMemcpy( void*  destination_buffer,\n",
    "    //                             void*  source_buffer,\n",
    "    //                             size_t num_bytes_to_copy,\n",
    "    //                             hipMemcpyKind kind\n",
    "    //                           )\n",
    "    // \n",
    "    //       If you get stuck, see the host-to-device call above\n",
    "    // /////////////////////////////////////////////////////////\n",
    "\n",
    "    /* Check for correct results */\n",
    "    for (int i=0; i<N; i++){\n",
    "        if(h_A[i] != 1){\n",
    "            printf(\"Error: h_A[%d] = %d instead of 1\\n\", i, h_A[i]);\n",
    "            exit(1);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /* Free CPU memory */\n",
    "    free(h_A);\n",
    "\n",
    "    /* Free Device memory */\n",
    "    gpuCheck( hipFree(d_A) );\n",
    "\n",
    "    printf(\"\\n==============================\\n\");\n",
    "    printf(\"__SUCCESS__\\n\");\n",
    "    printf(\"------------------------------\\n\");\n",
    "    printf(\"N                : %d\\n\", N);\n",
    "    printf(\"Blocks in Grid   : %d\\n\",  blk_in_grid);\n",
    "    printf(\"Threads per Block: %d\\n\",  thr_per_blk);\n",
    "    printf(\"==============================\\n\\n\");\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Instructions:`\n",
    "\n",
    "1. Locate the section in the code marked TODO.\n",
    "2. Implement the hipMemcpy call to copy the data from the device array d_A back to the host array h_A.\n",
    "3. Compile and run the program to ensure it executes correctly and prints __SUCCESS__ if all elements in the array have been incremented properly.\n",
    "4. If any element is not correctly incremented, the program should print an error message specifying the index and incorrect value.\n",
    "\n",
    "By completing this task, you will demonstrate your understanding of basic HIP memory management and kernel execution.\n",
    "\n",
    "You can find the solution in ./exercises/02_add_d2h_data_transfer/solution/add_one.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and test your program \n",
    "!hipcc --offload-arch=gfx908 -Wno-unused-result -o build/add_one exercises/02_add_d2h_data_transfer/add_one.cpp && build/add_one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise03: Squares each element of an array\n",
    "\n",
    "In this exercise, you will be working with a HIP program that squares each element of an array using GPU acceleration. The program is mostly complete, but there is one part that you need to implement. You can find the source code in [`03_square.cpp`](./exercises/03_complete_square_elements/square_elements.cpp).\n",
    "\n",
    "`Background:`\n",
    "\n",
    "The program performs the following steps:\n",
    "\n",
    "1. Defines a kernel function square_elements that squares each element of an integer array.\n",
    "2. Allocates memory on the host (CPU) for an array of size N.\n",
    "3. Initializes the host array elements to their index values.\n",
    "4. Allocates memory on the device (GPU) for an array of the same size.\n",
    "5. Copies the data from the host array to the device array.\n",
    "6. Configures the kernel launch parameters (number of threads per block and number of blocks in the grid).\n",
    "7. Launches the kernel to execute on the device.\n",
    "8. Copies the results back from the device array to the host array.\n",
    "9. Verifies the results.\n",
    "10. Frees the allocated memory on both the host and the device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "#include <stdio.h>\n",
    "#include <math.h>\n",
    "#include \"hip/hip_runtime.h\"\n",
    "\n",
    "/* Macro for checking GPU API return values */\n",
    "#define gpuCheck(call)                                                                          \\\n",
    "do{                                                                                             \\\n",
    "    hipError_t gpuErr = call;                                                                   \\\n",
    "    if(hipSuccess != gpuErr){                                                                   \\\n",
    "        printf(\"GPU API Error - %s:%d: '%s'\\n\", __FILE__, __LINE__, hipGetErrorString(gpuErr)); \\\n",
    "        exit(1);                                                                                \\\n",
    "    }                                                                                           \\\n",
    "}while(0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Task:`\n",
    "\n",
    "Your task is to complete the kernel function that squares each element of the array. The kernel should square the element only if its index is within bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "/* --------------------------------------------------\n",
    "Square elements kernel\n",
    "-------------------------------------------------- */\n",
    "__global__ void square_elements(int *A, int n)\n",
    "{\n",
    "    int id = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "\n",
    "\n",
    "    // TODO: Complete the kernel by squaring\n",
    "    //       all elements of the array.\n",
    "\n",
    "}\n",
    "\n",
    "/* --------------------------------------------------\n",
    "Main program\n",
    "-------------------------------------------------- */\n",
    "int main(int argc, char *argv[]){\n",
    "\n",
    "    /* Size of array */\n",
    "    int N = 1024 * 1024;\n",
    "\n",
    "    /* Bytes in N ints */\n",
    "    size_t bytes = N * sizeof(int);\n",
    "\n",
    "    /* Allocate memory for host array */\n",
    "    int *h_A = (int*)malloc(bytes);\n",
    "\n",
    "    /* Initialize host arrays */\n",
    "    for(int i=0; i<N; i++){\n",
    "        h_A[i] = i; \n",
    "    }    \n",
    "\n",
    "    /* Allocate memory for device array */\n",
    "    int *d_A;\n",
    "    gpuCheck( hipMalloc(&d_A, bytes) );\n",
    "\n",
    "    /* Copy data from host array to device array */\n",
    "    gpuCheck( hipMemcpy(d_A, h_A, bytes, hipMemcpyHostToDevice) );\n",
    "\n",
    "    /* Set kernel configuration parameters\n",
    "           thr_per_blk: number of threads per thread block\n",
    "           blk_in_grid: number of thread blocks in grid */\n",
    "    int thr_per_blk = 256;\n",
    "    int blk_in_grid = ceil( float(N) / thr_per_blk );\n",
    "\n",
    "    /* Launch kernel */\n",
    "    square_elements<<<blk_in_grid, thr_per_blk>>>(d_A, N);\n",
    "\n",
    "    /* Check for kernel launch errors */\n",
    "    gpuCheck( hipGetLastError() );\n",
    "\n",
    "    /* Check for kernel execution errors */\n",
    "    gpuCheck ( hipDeviceSynchronize() );\n",
    "\n",
    "    /* Copy data from device array to host array */\n",
    "    gpuCheck( hipMemcpy(h_A, d_A, bytes, hipMemcpyDeviceToHost) );\n",
    "\n",
    "    /* Check for correct results */\n",
    "    for (int i=0; i<N; i++){\n",
    "\n",
    "        if(h_A[i] != i * i){\n",
    "            printf(\"Error: h_A[%d] = %d instead of %d\\n\", i, h_A[i], i*i );\n",
    "            exit(1);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    /* Free CPU memory */\n",
    "    free(h_A);\n",
    "\n",
    "    /* Free Device memory */\n",
    "    gpuCheck( hipFree(d_A) );\n",
    "\n",
    "    printf(\"\\n==============================\\n\");\n",
    "    printf(\"__SUCCESS__\\n\");\n",
    "    printf(\"------------------------------\\n\");\n",
    "    printf(\"N                : %d\\n\", N);\n",
    "    printf(\"Blocks in Grid   : %d\\n\",  blk_in_grid);\n",
    "    printf(\"Threads per Block: %d\\n\",  thr_per_blk);\n",
    "    printf(\"==============================\\n\\n\");\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Instructions:`\n",
    "\n",
    "1. Locate the section in the kernel function square_elements marked TODO.\n",
    "2. Implement the logic to square each element of the array.\n",
    "3. Compile and run the program to ensure it executes correctly and prints __SUCCESS__ if all elements in the array have been squared properly.\n",
    "4. If any element is not correctly squared, the program should print an error message specifying the index and incorrect value.\n",
    "\n",
    "By completing this task, you will demonstrate your understanding of writing and executing basic HIP kernels for element-wise operations on arrays.\n",
    "\n",
    "You can find the solution in ./exercises/03_complete_square_elements/solution/square_elements.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and test your program \n",
    "!hipcc --offload-arch=gfx908 -Wno-unused-result -o build/squares exercises/03_complete_square_elements/square_elements.cpp && build/squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise04: Multiply two square matrices\n",
    "\n",
    "In this exercise, you will be working with a HIP program that multiplies two square matrices using GPU acceleration. The program is mostly complete, but there are a few parts that you need to implement. You can find the source code in [`04_multiply.cpp`](./exercises/04_complete_matrix_multiply/matrix_multiply.cpp).\n",
    "\n",
    "`Background:`\n",
    "\n",
    "The program performs the following steps:\n",
    "\n",
    "1. Defines a kernel function matrix_multiply that multiplies two NxN matrices.\n",
    "2. Allocates memory on the host (CPU) for three NxN matrices: A, B, and C.\n",
    "3. Initializes the host matrices A and B with specific values and sets C to zero.\n",
    "4. Allocates memory on the device (GPU) for the matrices.\n",
    "5. Copies the data from the host matrices to the device matrices.\n",
    "6. Configures the kernel launch parameters (number of threads per block and number of blocks in the grid).\n",
    "7. Launches the kernel to execute on the device.\n",
    "8. Copies the result back from the device matrix C to the host matrix.\n",
    "9. Verifies the results.\n",
    "10. Frees the allocated memory on both the host and the device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "#include <stdio.h>\n",
    "#include <math.h>\n",
    "#include \"hip/hip_runtime.h\"\n",
    "\n",
    "/* Macro for checking GPU API return values */\n",
    "#define gpuCheck(call)                                                                          \\\n",
    "do{                                                                                             \\\n",
    "    hipError_t gpuErr = call;                                                                   \\\n",
    "    if(hipSuccess != gpuErr){                                                                   \\\n",
    "        printf(\"GPU API Error - %s:%d: '%s'\\n\", __FILE__, __LINE__, hipGetErrorString(gpuErr)); \\\n",
    "        exit(1);                                                                                \\\n",
    "    }                                                                                           \\\n",
    "}while(0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Task:`\n",
    "\n",
    "Your task is to complete the kernel function that performs the matrix multiplication. Specifically, you need to:\n",
    "\n",
    "1. Identify the correct elements of matrices A and B to multiply.\n",
    "\n",
    "2. Store the result back into matrix C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "/* --------------------------------------------------\n",
    "Matrix multiply kernel\n",
    "-------------------------------------------------- */\n",
    "__global__ void matrix_multiply(double *A, double *B, double *C, int n)\n",
    "{\n",
    "    int col = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    int row = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "\n",
    "    if (col < n && row < n){\n",
    "\n",
    "        int index = n * row + col;\n",
    "        double element = 0.0;\n",
    "\n",
    "        for (int i=0; i<n; i++){\n",
    "\n",
    "            int row_index = n * row + i;\n",
    "            int col_index = n * i   + col;\n",
    "\n",
    "            // TODO: Look at row_index and col_index above\n",
    "            //       and determine which is the correct \n",
    "            //       element for A and which is the correct\n",
    "            //       element for B below.\n",
    "            element = element + A[??] * B[??]; \n",
    "        }\n",
    "\n",
    "        // TODO: Copy the result back to the C array here\n",
    "    }\n",
    "}\n",
    "\n",
    "/* --------------------------------------------------\n",
    "Main program\n",
    "-------------------------------------------------- */\n",
    "int main(int argc, char *argv[]){\n",
    "\n",
    "    /* Size of NxN matrix */\n",
    "    int N = 1024;\n",
    "\n",
    "    /* Bytes in matrix in double precision */\n",
    "    size_t bytes = N * N * sizeof(double);\n",
    "\n",
    "    double *h_A = (double*)malloc(bytes);\n",
    "    double *h_B = (double*)malloc(bytes);\n",
    "    double *h_C = (double*)malloc(bytes);\n",
    "\n",
    "    /* Initialize host arrays */\n",
    "    for(int i=0; i<N; i++){\n",
    "        for(int j=0; j<N; j++){\n",
    "\n",
    "            int index = N * i + j;\n",
    "\n",
    "            h_A[index] = j + 1.0;\n",
    "            h_B[index] = 1.0 / (i + 1.0);\n",
    "            h_C[index] = 0.0;\n",
    "        }\n",
    "    }    \n",
    "\n",
    "    /* Allocate memory for device matrices */\n",
    "    double *d_A, *d_B, *d_C;\n",
    "    gpuCheck( hipMalloc(&d_A, bytes) );\n",
    "    gpuCheck( hipMalloc(&d_B, bytes) );\n",
    "    gpuCheck( hipMalloc(&d_C, bytes) );\n",
    "\n",
    "    /* Copy data from host matrices to device matricesL */\n",
    "    gpuCheck( hipMemcpy(d_A, h_A, bytes, hipMemcpyHostToDevice) );\n",
    "    gpuCheck( hipMemcpy(d_B, h_B, bytes, hipMemcpyHostToDevice) );\n",
    "    gpuCheck( hipMemcpy(d_C, h_C, bytes, hipMemcpyHostToDevice) );\n",
    "\n",
    "    /* Set kernel configuration parameters\n",
    "           thr_per_blk: number of threads per thread block\n",
    "           blk_in_grid: number of thread blocks in grid\n",
    "    \n",
    "       (NOTE: dim3 is a c struct with member variables x, y, z) */\n",
    "    dim3 thr_per_blk( 16, 16, 1 );\n",
    "    dim3 blk_in_grid( ceil( float(N) / thr_per_blk.x), ceil(float(N) / thr_per_blk.y), 1 );\n",
    "\n",
    "    /* Launch matrix addition kernel */\n",
    "    matrix_multiply<<<blk_in_grid, thr_per_blk>>>(d_A, d_B, d_C, N);\n",
    "\n",
    "    /* Check for kernel launch errors */\n",
    "    gpuCheck( hipGetLastError() );\n",
    "\n",
    "    /* Check for kernel execution errors */\n",
    "    gpuCheck ( hipDeviceSynchronize() );\n",
    "\n",
    "    /* Copy data from device matrix to host matrix (only need result, d_C) */\n",
    "    gpuCheck( hipMemcpy(h_C, d_C, bytes, hipMemcpyDeviceToHost) );\n",
    "\n",
    "    /* Check for correct results */\n",
    "    double tolerance = 1.0e-14;\n",
    "\n",
    "    for(int i=0; i<N; i++){\n",
    "        for(int j=0; j<N; j++){\n",
    "                \n",
    "            int index = N * i + j;\n",
    "            if( isnan(h_C[index]) || fabs(h_C[index] - N ) > tolerance ){\n",
    "                printf(\"Error: h_C[%d] = %0.14f instead of %d\\n\", index, h_C[index], N);\n",
    "                exit(1);\n",
    "            }\n",
    "        }\n",
    "    }   \n",
    "\n",
    "    /* Free CPU memory */\n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(h_C);\n",
    "\n",
    "    /* Free Device memory */\n",
    "    gpuCheck( hipFree(d_A) );\n",
    "    gpuCheck( hipFree(d_B) );\n",
    "    gpuCheck( hipFree(d_C) );\n",
    "\n",
    "    printf(\"\\n==============================\\n\");\n",
    "    printf(\"__SUCCESS__\\n\");\n",
    "    printf(\"------------------------------\\n\");\n",
    "    printf(\"N                  : %d\\n\", N);\n",
    "    printf(\"X Blocks in Grid   : %d\\n\",  blk_in_grid.x);\n",
    "    printf(\"X Threads per Block: %d\\n\",  thr_per_blk.x);\n",
    "    printf(\"Y Blocks in Grid   : %d\\n\",  blk_in_grid.y);\n",
    "    printf(\"Y Threads per Block: %d\\n\",  thr_per_blk.y);\n",
    "    printf(\"==============================\\n\\n\");\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Instructions:`\n",
    "\n",
    "1. Locate the TODO comments in the kernel function matrix_multiply.\n",
    "2. Determine the correct indices for accessing the elements of matrices A and B.\n",
    "3. Write the code to store the computed value into matrix C.\n",
    "4. Compile and run the program to ensure it executes correctly and prints __SUCCESS__ if all elements in the result matrix C are computed correctly.\n",
    "5. If any element is not computed correctly, the program should print an error message specifying the index and incorrect value.\n",
    "\n",
    "By completing this task, you will demonstrate your understanding of writing and executing basic HIP kernels for matrix operations.\n",
    "\n",
    "You can find the solution in ./exercises/04_complete_matrix_multiply/solution/matrix_multiply.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and test your program \n",
    "!hipcc --offload-arch=gfx908 -Wno-unused-result -o build/matrix_multiply exercises/04_complete_matrix_multiply/matrix_multiply.cpp && build/matrix_multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise05: Compare performance against the hipBLAS version of DGEMM\n",
    "\n",
    "In this exercise, we will use the `matrix_multiply` kernel we completed in `04_complete_the_kernel` and compare its performance against the hipBLAS version of DGEMM. \n",
    "\n",
    "You will not need to make any code changes. Instead, you will simply compile the code and submit the job. This will run the code under the `rocprof` profiling tool and parse the results. \n",
    "\n",
    "To compile and run:\n",
    "```\n",
    "$ make\n",
    "\n",
    "$ sbatch submit.sh\n",
    "```\n",
    "\n",
    "To view the resulting profile, run the python script:\n",
    "```\n",
    "./parse_output.py\n",
    "```\n",
    "\n",
    "It should be clear from the performance difference that using existing libraries is typically the right choice instead of re-inventing the (slower) wheel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise06: Hipify the CUDA pingpong code\n",
    "\n",
    "This code sends data back and forth between the host and device 50 times and calculates the bandwidth. \n",
    "\n",
    "Your job is to `hipify` the code, then compile and run it. \n",
    "NOTE: The `#include \"hip/hip_runtime.h\" doesn't always get added when a code is `hipify`-ed, so it might need to be added manually.\n",
    "\n",
    "To compile and run:\n",
    "```\n",
    "$ make\n",
    " \n",
    "$ sbatch submit.sh\n",
    "```\n",
    "\n",
    "Recall that the CPU and GPU are connected with PCIe4 (x16), which has a peak bandwidth of 32 GB/s. What percentage of the peak performance do we achieve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise07: Multiply two square matrices using shared memory\n",
    "\n",
    "In this exercise, you will be working with a HIP program that multiplies two square matrices using shared memory on the GPU for improved performance. The program is mostly complete, but there are a few parts that you need to implement. You can find the source code in [`07_multiply_shared.cpp`](./exercises/07_matrix_multiply_shared/matrix_multiply.cpp).\n",
    "\n",
    "`Background:`\n",
    "\n",
    "The program performs the following steps:\n",
    "\n",
    "1. Defines a kernel function matrix_multiply that multiplies two NxN matrices using shared memory.\n",
    "2. Allocates memory on the host (CPU) for three NxN matrices: A, B, and C.\n",
    "3. Initializes the host matrices A and B with specific values and sets C to zero.\n",
    "4. Allocates memory on the device (GPU) for the matrices.\n",
    "5. Copies the data from the host matrices to the device matrices.\n",
    "6. Configures the kernel launch parameters (number of threads per block and number of blocks in the grid).\n",
    "7. Launches the kernel to execute on the device.\n",
    "8. Copies the result back from the device matrix C to the host matrix.\n",
    "9. Verifies the results.\n",
    "10. Frees the allocated memory on both the host and the device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "#include <stdio.h>\n",
    "#include <math.h>\n",
    "#include \"hip/hip_runtime.h\"\n",
    "\n",
    "/* Macro for checking GPU API return values */\n",
    "#define gpuCheck(call)                                                                          \\\n",
    "do{                                                                                             \\\n",
    "    hipError_t gpuErr = call;                                                                   \\\n",
    "    if(hipSuccess != gpuErr){                                                                   \\\n",
    "        printf(\"GPU API Error - %s:%d: '%s'\\n\", __FILE__, __LINE__, hipGetErrorString(gpuErr)); \\\n",
    "        exit(1);                                                                                \\\n",
    "    }                                                                                           \\\n",
    "}while(0)\n",
    "\n",
    "#define THREADS_PER_BLOCK_X 16\n",
    "#define THREADS_PER_BLOCK_Y 16\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Task:`\n",
    "\n",
    "Your task is to complete the kernel function that performs the matrix multiplication using shared memory. Specifically, you need to:\n",
    "\n",
    "1. Read data from global memory into shared memory.\n",
    "\n",
    "2. Perform the matrix multiplication using shared memory.\n",
    "\n",
    "3. Store the result back into the global memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "/* --------------------------------------------------\n",
    "Matrix multiply kernel\n",
    "-------------------------------------------------- */\n",
    "__global__ void matrix_multiply(double *A, double *B, double *C, int n)\n",
    "{\n",
    "    __shared__ double s_A[THREADS_PER_BLOCK_Y][THREADS_PER_BLOCK_X];\n",
    "    __shared__ double s_B[THREADS_PER_BLOCK_Y][THREADS_PER_BLOCK_X];\n",
    "\n",
    "    int col  = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    int row  = blockDim.y * blockIdx.y + threadIdx.y;\n",
    "\n",
    "    int lcol = threadIdx.x;\n",
    "    int lrow = threadIdx.y;\n",
    "\n",
    "    int index  = n * row + col;\n",
    "\n",
    "    if (col < n && row < n){\n",
    "\n",
    "        int THREADS_PER_BLOCK = THREADS_PER_BLOCK_Y;\n",
    "        int num_chunks        = n / THREADS_PER_BLOCK;\n",
    "\n",
    "        double element = 0.0;\n",
    "\n",
    "        for (int chunk=0; chunk<num_chunks; chunk++){ \n",
    "\n",
    "            // TODO: Read data from global GPU memory into shared memory\n",
    "\n",
    "            __syncthreads();\n",
    "\n",
    "            for (int i=0; i<THREADS_PER_BLOCK; i++){\n",
    "                element = element + s_A[lrow][i] * s_B[i][lcol];\n",
    "            }\n",
    "\n",
    "            __syncthreads();\n",
    "        }\n",
    "\n",
    "        C[index] = element;\n",
    "    }\n",
    "}\n",
    "\n",
    "/* --------------------------------------------------\n",
    "Main program\n",
    "-------------------------------------------------- */\n",
    "int main(int argc, char *argv[]){\n",
    "\n",
    "    /* Size of NxN matrix */\n",
    "    int N = 1024;\n",
    "\n",
    "    /* Bytes in matrix in double precision */\n",
    "    size_t bytes = N * N * sizeof(double);\n",
    "\n",
    "    double *h_A = (double*)malloc(bytes);\n",
    "    double *h_B = (double*)malloc(bytes);\n",
    "    double *h_C = (double*)malloc(bytes);\n",
    "\n",
    "    /* Initialize host arrays */\n",
    "    for(int i=0; i<N; i++){\n",
    "        for(int j=0; j<N; j++){\n",
    "\n",
    "            int index = N * i + j;\n",
    "\n",
    "            h_A[index] = j + 1.0;\n",
    "            h_B[index] = 1.0 / (i + 1.0);\n",
    "            h_C[index] = 0.0;\n",
    "        }\n",
    "    }    \n",
    "\n",
    "    /* Allocate memory for device matrices */\n",
    "    double *d_A, *d_B, *d_C;\n",
    "    gpuCheck( hipMalloc(&d_A, bytes) );\n",
    "    gpuCheck( hipMalloc(&d_B, bytes) );\n",
    "    gpuCheck( hipMalloc(&d_C, bytes) );\n",
    "\n",
    "    /* Copy data from host matrices to device matricesL */\n",
    "    gpuCheck( hipMemcpy(d_A, h_A, bytes, hipMemcpyHostToDevice) );\n",
    "    gpuCheck( hipMemcpy(d_B, h_B, bytes, hipMemcpyHostToDevice) );\n",
    "    gpuCheck( hipMemcpy(d_C, h_C, bytes, hipMemcpyHostToDevice) );\n",
    "\n",
    "    /* Set kernel configuration parameters\n",
    "           thr_per_blk: number of threads per thread block\n",
    "           blk_in_grid: number of thread blocks in grid\n",
    "    \n",
    "       (NOTE: dim3 is a c struct with member variables x, y, z) */\n",
    "    dim3 thr_per_blk( THREADS_PER_BLOCK_X, THREADS_PER_BLOCK_Y, 1 );\n",
    "    dim3 blk_in_grid( ceil( float(N) / thr_per_blk.x), ceil(float(N) / thr_per_blk.y), 1 );\n",
    "\n",
    "    /* Launch matrix addition kernel */\n",
    "    matrix_multiply<<<blk_in_grid, thr_per_blk>>>(d_A, d_B, d_C, N);\n",
    "\n",
    "    /* Check for kernel launch errors */\n",
    "    gpuCheck( hipGetLastError() );\n",
    "\n",
    "    /* Check for kernel execution errors */\n",
    "    gpuCheck ( hipDeviceSynchronize() );\n",
    "\n",
    "    /* Copy data from device matrix to host matrix (only need result, d_C) */\n",
    "    gpuCheck( hipMemcpy(h_C, d_C, bytes, hipMemcpyDeviceToHost) );\n",
    "\n",
    "    /* Check for correct results */\n",
    "    double tolerance = 1.0e-14;\n",
    "\n",
    "    for(int i=0; i<N; i++){\n",
    "        for(int j=0; j<N; j++){\n",
    "                \n",
    "            int index = N * i + j;\n",
    "            if( isnan(h_C[index]) || fabs(h_C[index] - N ) > tolerance ){\n",
    "                printf(\"Error: h_C[%d] = %0.14f instead of %d\\n\", index, h_C[index], N);\n",
    "                exit(1);\n",
    "            }\n",
    "        }\n",
    "    }   \n",
    "\n",
    "    /* Free CPU memory */\n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(h_C);\n",
    "\n",
    "    /* Free Device memory */\n",
    "    gpuCheck( hipFree(d_A) );\n",
    "    gpuCheck( hipFree(d_B) );\n",
    "    gpuCheck( hipFree(d_C) );\n",
    "\n",
    "    printf(\"\\n==============================\\n\");\n",
    "    printf(\"__SUCCESS__\\n\");\n",
    "    printf(\"------------------------------\\n\");\n",
    "    printf(\"N                  : %d\\n\", N);\n",
    "    printf(\"X Blocks in Grid   : %d\\n\",  blk_in_grid.x);\n",
    "    printf(\"X Threads per Block: %d\\n\",  thr_per_blk.x);\n",
    "    printf(\"Y Blocks in Grid   : %d\\n\",  blk_in_grid.y);\n",
    "    printf(\"Y Threads per Block: %d\\n\",  thr_per_blk.y);\n",
    "    printf(\"==============================\\n\\n\");\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Instructions:`\n",
    "\n",
    "1. Locate the TODO comments in the kernel function matrix_multiply.\n",
    "2. Read data from global memory into the shared memory arrays s_A and s_B.\n",
    "3. Write the code to store the computed value into matrix C.\n",
    "4. Compile and run the program to ensure it executes correctly and prints __SUCCESS__ if all elements in the result matrix C are computed correctly.\n",
    "5. If any element is not computed correctly, the program should print an error message specifying the index and incorrect value.\n",
    "\n",
    "By completing this task, you will demonstrate your understanding of writing and executing basic HIP kernels for matrix operations using shared memory to optimize performance.\n",
    "\n",
    "You can find the solution in ./exercises/07_matrix_multiply_shared/solution/matrix_multiply.cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run and test your program \n",
    "!hipcc --offload-arch=gfx908 -Wno-unused-result -o build/matrix_multiply_shared exercises/07_matrix_multiply_shared/matrix_multiply.cpp && build/matrix_multiply_shared"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
