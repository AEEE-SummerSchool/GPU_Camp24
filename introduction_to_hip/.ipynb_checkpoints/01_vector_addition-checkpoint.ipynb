{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"><h1>Vector Addition with HIP C/C++</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prerequisites\n",
    "\n",
    "To get the most out of this lab you should already be able to:\n",
    "\n",
    "- Declare variables, write loops, and use if / else statements in C.\n",
    "- Define and invoke functions in C.\n",
    "- Allocate arrays in C.\n",
    "\n",
    "No previous HIP knowledge is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Objectives\n",
    "\n",
    "By the time you complete this lab, you will be able to:\n",
    "\n",
    "- Write, compile, and run C/C++ programs that both call CPU functions and **launch** GPU **kernels**.\n",
    "- Control parallel **thread hierarchy** using **execution configuration**.\n",
    "- Refactor serial loops to execute their iterations in parallel on a GPU.\n",
    "- Allocate and free memory available to both CPUs and GPUs.\n",
    "- Handle errors generated by HIP code.\n",
    "- Accelerate CPU-only applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Accelerated Systems\n",
    "\n",
    "*Accelerated systems*, also referred to as *heterogeneous systems*, are those composed of both CPUs and GPUs. Accelerated systems run CPU programs which in turn, launch functions that will benefit from the massive parallelism providied by GPUs. This lab environment is an accelerated system which includes an NVIDIA GPU. Information about this GPU can be queried with the `rocm-smi` (*Systems Management Interface*) command line command. Issue the `rocm-smi` command now, by `CTRL` + clicking on the code execution cell below. You will find these cells throughout this lab any time you need to execute code. The output from running the command will be printed just below the code execution cell after the code runs. After running the code execution block immediately below, take care to find and note the name of the GPU in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========================================= ROCm System Management Interface =========================================\n",
      "=================================================== Concise Info ===================================================\n",
      "Device  [Model : Revision]    Temp    Power     Partitions      SCLK  MCLK     Fan  Perf  PwrCap       VRAM%  GPU%  \n",
      "\u001b[3m        Name (20 chars)       (Edge)  (Socket)  (Mem, Compute)                                                      \u001b[0m\n",
      "====================================================================================================================\n",
      "0       [0xb002 : 0xc1]       33.0Â°C  11.189W   N/A, N/A        None  2800Mhz  0%   auto  Unsupported    3%   1%    \n",
      "        0x15bf                                                                                                      \n",
      "====================================================================================================================\n",
      "=============================================== End of ROCm SMI Log ================================================\n"
     ]
    }
   ],
   "source": [
    "!rocm-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Writing Application Code for the GPU\n",
    "\n",
    "HIP provides extensions for many common programming languages, in the case of this lab, C/C++. These language extensions easily allow developers to run functions in their source code on a GPU.\n",
    "\n",
    "Below is a `.cpp` file. It contains two functions, the first which will run on the CPU, the second which will run on the GPU. Spend a little time identifying the differences between the functions, both in terms of how they are defined, and how they are invoked.\n",
    "\n",
    "```cpp\n",
    "void CPUFunction()\n",
    "{\n",
    "  printf(\"This function is defined to run on the CPU.\\n\");\n",
    "}\n",
    "\n",
    "__global__ void GPUFunction()\n",
    "{\n",
    "  printf(\"This function is defined to run on the GPU.\\n\");\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "  CPUFunction();\n",
    "\n",
    "  GPUFunction<<<1, 1>>>();\n",
    "  HIPDeviceSynchronize();\n",
    "}\n",
    "```\n",
    "\n",
    "Here are some important lines of code to highlight, as well as some other common terms used in accelerated computing:\n",
    "\n",
    "`__global__ void GPUFunction()`\n",
    "  - The `__global__` keyword indicates that the following function will run on the GPU, and can be invoked **globally**, which in this context means either by the CPU, or, by the GPU.\n",
    "  - Often, code executed on the CPU is referred to as **host** code, and code running on the GPU is referred to as **device** code.\n",
    "  - Notice the return type `void`. It is required that functions defined with the `__global__` keyword return type `void`.\n",
    "\n",
    "`GPUFunction<<<1, 1>>>();`\n",
    "  - Typically, when calling a function to run on the GPU, we call this function a **kernel**, which is **launched**.\n",
    "  - When launching a kernel, we must provide an **execution configuration**, which is done by using the `<<< ... >>>` syntax just prior to passing the kernel any expected arguments.\n",
    "  - At a high level, execution configuration allows programmers to specify the **thread hierarchy** for a kernel launch, which defines the number of thread groupings (called **blocks**), as well as how many **threads** to execute in each block. Execution configuration will be explored at great length later in the lab, but for the time being, notice the kernel is launching with `1` block of threads (the first execution configuration argument) which contains `1` thread (the second configuration argument).\n",
    "\n",
    "`HIPDeviceSynchronize();`\n",
    "  - Unlike much C/C++ code, launching kernels is **asynchronous**: the CPU code will continue to execute *without waiting for the kernel launch to complete*.\n",
    "  - A call to `HIPDeviceSynchronize`, a function provided by the HIP runtime, will cause the host (CPU) code to wait until the device (GPU) code completes, and only then resume execution on the CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Compiling and Running Accelerated HIP Code\n",
    "\n",
    "This section contains details about the `hipcc` command you issued above to compile and run your `.cpp` program.\n",
    "\n",
    "The HIP platform ships with the [**ROCm HIP Compiler**](https://rocm.docs.amd.com/projects/HIPCC/en/latest/index.html) `hipcc`, which can compile HIP accelerated applications, both the host, and the device code they contain. For the purposes of this lab, `hipcc` discussion with be pragmatically scoped to suit our immediate needs. After completing the lab, For anyone interested in a deeper dive into `hipcc`, start with [the documentation](https://rocm.docs.amd.com/projects/HIPCC/en/latest/index.html).\n",
    "\n",
    "`hipcc` will be very familiar to experienced `gcc` users. Compiling, for example, a `some-HIP.cpp` file, is simply:\n",
    "\n",
    "`hipcc -o out some-HIP.cpp `\n",
    "  - `hipcc` is the command line command for using the `hipcc` compiler.\n",
    "  - `some-HIP.cpp` is passed as the file to compile.\n",
    "  - The `o` flag is used to specify the output file for the compiled program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Exercise: Accelerate Vector Addition Application\n",
    "\n",
    "The following challenge involves accelerating a CPU-only vector addition program, which, while not the most sophisticated program, will give you an opportunity to focus on what you have learned about GPU-accelerating an application with HIP.\n",
    "\n",
    "[`01_vector_addition.cpp`](./examples/01_vector_addition/vector_addition.cpp) contains a functioning CPU-only vector addition application. You need to write a HIP kernel on the GPU and to do its work in parallel.\n",
    "\n",
    "![vec_add_01](./images/vec_add_01.png)\n",
    "\n",
    "![vec_add_02](./images/vec_add_02.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "/* --------------------------------------------------\n",
    "Include lib\n",
    "-------------------------------------------------- */\n",
    "#include <stdio.h>\n",
    "#include <math.h>\n",
    "#include \"hip/hip_runtime.h\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "/* --------------------------------------------------\n",
    "vector addition kernel\n",
    "-------------------------------------------------- */\n",
    "__global__ void vector_addition(double *A, double *B, double *C, int n)\n",
    "{\n",
    "    int id = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if (id < n) C[id] = A[id] + B[id];\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cpp\n",
    "/* --------------------------------------------------\n",
    "Main program\n",
    "-------------------------------------------------- */\n",
    "int main(int argc, char *argv[]){\n",
    "\n",
    "    /* Size of array */\n",
    "    int N = 1024 * 1024;\n",
    "\n",
    "    /* Bytes in array in double precision */\n",
    "    size_t bytes = N * sizeof(double);\n",
    "\n",
    "    /* Allocate memory for host arrays */\n",
    "    double *h_A = (double*)malloc(bytes);\n",
    "    double *h_B = (double*)malloc(bytes);\n",
    "    double *h_C = (double*)malloc(bytes);\n",
    "\n",
    "    /* Initialize host arrays */\n",
    "    for(int i=0; i<N; i++){\n",
    "        h_A[i] = sin(i) * sin(i); \n",
    "        h_B[i] = cos(i) * cos(i);\n",
    "        h_C[i] = 0.0;\n",
    "    }    \n",
    "\n",
    "    /* Allocate memory for device arrays */\n",
    "    double *d_A, *d_B, *d_C;\n",
    "    hipMalloc(&d_A, bytes);\n",
    "    hipMalloc(&d_B, bytes);\n",
    "    hipMalloc(&d_C, bytes);\n",
    "\n",
    "    /* Copy data from host arrays to device arrays */\n",
    "    hipMemcpy(d_A, h_A, bytes, hipMemcpyHostToDevice);\n",
    "    hipMemcpy(d_B, h_B, bytes, hipMemcpyHostToDevice);\n",
    "    hipMemcpy(d_C, h_C, bytes, hipMemcpyHostToDevice);\n",
    "\n",
    "    /* Set kernel configuration parameters\n",
    "           thr_per_blk: number of threads per thread block\n",
    "           blk_in_grid: number of thread blocks in grid */\n",
    "    int thr_per_blk = 256;\n",
    "    int blk_in_grid = ceil( float(N) / thr_per_blk );\n",
    "\n",
    "    /* Launch vector addition kernel */\n",
    "    vector_addition<<<blk_in_grid, thr_per_blk>>>(d_A, d_B, d_C, N);\n",
    "\n",
    "    /* Copy data from device array to host array (only need result, d_C) */\n",
    "    hipMemcpy(h_C, d_C, bytes, hipMemcpyDeviceToHost);\n",
    "\n",
    "    /* Check for correct results */\n",
    "    double sum       = 0.0;\n",
    "    double tolerance = 1.0e-14;\n",
    "\n",
    "    for(int i=0; i<N; i++){\n",
    "        sum = sum + h_C[i];\n",
    "    } \n",
    "\n",
    "    if( fabs( (sum / N) - 1.0 ) > tolerance ){\n",
    "        printf(\"Error: Sum/N = %0.2f instead of ~1.0\\n\", sum / N);\n",
    "        exit(1);\n",
    "    }\n",
    "\n",
    "    /* Free CPU memory */\n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(h_C);\n",
    "\n",
    "    /* Free Device memory */\n",
    "    hipFree(d_A);\n",
    "    hipFree(d_B);\n",
    "    hipFree(d_C);\n",
    "\n",
    "    printf(\"\\n==============================\\n\");\n",
    "    printf(\"__SUCCESS__\\n\");\n",
    "    printf(\"------------------------------\\n\");\n",
    "    printf(\"N                : %d\\n\", N);\n",
    "    printf(\"Blocks in Grid   : %d\\n\", blk_in_grid);\n",
    "    printf(\"Threads per Block: %d\\n\", thr_per_blk);\n",
    "    printf(\"==============================\\n\\n\"); \n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Sum/N = 0.00 instead of ~1.0\n"
     ]
    }
   ],
   "source": [
    "!mkdir build\n",
    "!hipcc --offload-arch=gfx908 -Wno-unused-result -o build/vector_add examples/01_vector_addition/vector_addition.cpp && build/vector_add"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
